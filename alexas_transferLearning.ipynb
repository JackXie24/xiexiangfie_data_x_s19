{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sk_audio',\n",
       " 'kr_audio',\n",
       " 'cs_audio',\n",
       " 'ss_audio',\n",
       " 'pg_audio',\n",
       " 'jx_audio',\n",
       " 'rg_audio',\n",
       " 'ac_audio',\n",
       " 'pr_audio',\n",
       " 'md_audio']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = os.listdir('Data')\n",
    "i.pop(3)\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk_audio.csv\n",
      "kr_audio.csv\n",
      "cs_audio.csv\n",
      "ss_audio.csv\n",
      "pg_audio.csv\n",
      "jx_audio.csv\n",
      "rg_audio.csv\n",
      "ac_audio.csv\n",
      "pr_audio.csv\n",
      "md_audio.csv\n"
     ]
    }
   ],
   "source": [
    "for ele in i:\n",
    "    print(ele+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ele in i:\n",
    "    count=-1\n",
    "    with open('Data/'+ele+'/'+ele+'_df.csv') as csvfile:\n",
    "        spamreader = csv.reader(csvfile, delimiter=',')\n",
    "        for row in spamreader:\n",
    "            count+=1\n",
    "            if count == 0:\n",
    "                continue    \n",
    "            if not os.path.exists('spectrograms/' + row[2]):\n",
    "                os.makedirs('spectrograms/' + row[2])\n",
    "                os.makedirs('spectrograms/test/' + row[2])\n",
    "            y, sr = librosa.load(\"Data/\"+ele+\"/\"+row[1])\n",
    "            # make and display a mel-scaled power spectrogram\n",
    "            S = librosa.feature.melspectrogram(y, sr=sr, n_mels=128)\n",
    "            # Convert to log scale (dB). Use the peak power as reference.\n",
    "            log_S = librosa.power_to_db(S)\n",
    "            fig = plt.figure(figsize=(12,4))\n",
    "            ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "            ax.set_axis_off()\n",
    "            fig.add_axes(ax)\n",
    "            # Display the spectrogram on a mel scale\n",
    "            # sample rate and hop length parameters are used to render the time axis\n",
    "            librosa.display.specshow(log_S, sr=sr, x_axis='time', y_axis='mel')\n",
    "\n",
    "            # Make the figure layout compact\n",
    "\n",
    "            #plt.show()\n",
    "            plt.savefig('spectrograms/' + row[2] + '/' + row[1] + '.jpg')\n",
    "            plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Single Test Faile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load('testN/rg_audio/rg_val_sent002.wav')\n",
    "# make and display a mel-scaled power spectrogram\n",
    "S = librosa.feature.melspectrogram(y, sr=sr, n_mels=128)\n",
    "# Convert to log scale (dB). Use the peak power as reference.\n",
    "log_S = librosa.power_to_db(S)\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "ax.set_axis_off()\n",
    "fig.add_axes(ax)\n",
    "# Display the spectrogram on a mel scale        \n",
    "# sample rate and hop length parameters are used to render the time axis\n",
    "librosa.display.specshow(log_S, sr=sr, x_axis='time', y_axis='mel')\n",
    "# Make the figure layout compact\n",
    "#plt.show()\n",
    "plt.savefig('spectrograms/test/rene_g/rg2.jpg')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-08 00:37:32.901641: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2019-04-08 00:37:32.901672: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2019-04-08 00:37:32.901683: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2019-04-08 00:37:32.901692: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2019-04-08 00:37:32.901700: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2019-04-08 00:37:34.303935: W tensorflow/core/framework/op_def_util.cc:332] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().\n",
      "\n",
      "Evaluation time (1-image): 2.154s\n",
      "\n",
      "pooja r 0.6315062\n",
      "rene g 0.12796201\n",
      "jack x 0.10863231\n",
      "mikio d 0.07817484\n",
      "ken r 0.025658118\n"
     ]
    }
   ],
   "source": [
    "!python label_image.py \\\n",
    "    --graph=retrained_graph.pb\\\n",
    "    --labels=retrained_labels.txt\\\n",
    "    --image=spectrograms/test/mikio_d/md2.jpg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serhad 2\n",
    "both mikio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard --logdir training_summaries\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
